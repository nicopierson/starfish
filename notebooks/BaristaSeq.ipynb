{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starfish BaristaSeq Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "from skimage.transform import SimilarityTransform, warp\n",
    "from tqdm import tqdm\n",
    "\n",
    "import starfish\n",
    "import starfish.data\n",
    "from starfish.spots import SpotFinder\n",
    "from starfish.types import Axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaristaSeq is an assay that sequences padlock-probe initiated rolling circle amplified spots using a one-hot codebook. The publication for this assay can be found [here](https://www.ncbi.nlm.nih.gov/pubmed/29190363).\n",
    "\n",
    "The first step in BaristaSeq is to do some rough registration. For this data, the rough registration has been done for us by the authors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1550ad7b8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:02<00:00, 92.36it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 96.92it/s]\n"
     ]
    }
   ],
   "source": [
    "exp = starfish.data.BaristaSeq()\n",
    "fov = exp['fov_000']\n",
    "img = fov.get_image('primary')\n",
    "nissl = fov.get_image('nuclei')  # this is actually dots, should change this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of BaristaSeq is done in 2-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x15aa95550>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(nissl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 164.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.53it/s]\n"
     ]
    }
   ],
   "source": [
    "z_projected_image = img.max_proj(Axes.ZPLANE)\n",
    "z_projected_nissl = nissl.max_proj(Axes.ZPLANE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight miss-alignment of the C channel in the microscope used to process the data. We transform the data to account for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SimilarityTransform(translation=(1.9, -0.4))\n",
    "channels = (0,)\n",
    "rounds = np.arange(img.num_rounds)\n",
    "slice_indices = product(channels, rounds)\n",
    "\n",
    "for ch, round_, in slice_indices:\n",
    "    selector = {Axes.ROUND: round_, Axes.CH: ch, Axes.ZPLANE: 0}\n",
    "    tile = z_projected_image.get_slice(selector)[0]\n",
    "    transformed = warp(tile, transform)\n",
    "    z_projected_image.set_slice(\n",
    "        selector=selector,\n",
    "        data=transformed.astype(np.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 171.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from skimage.feature import register_translation  # noqa\n",
    "from skimage.transform import warp  # noqa\n",
    "from skimage.transform import SimilarityTransform  # noqa\n",
    "from functools import partial\n",
    "\n",
    "def _register_imagestack(target_image, reference_image, upsample_factor=5):\n",
    "    target_image = np.squeeze(target_image)\n",
    "    reference_image = np.squeeze(reference_image)\n",
    "    shift, error, phasediff = register_translation(target_image, reference_image, upsample_factor=1)\n",
    "    return SimilarityTransform(translation=shift)\n",
    "\n",
    "projection = z_projected_image.max_proj(Axes.CH, Axes.ZPLANE)\n",
    "reference_image = projection.sel({Axes.ROUND: 1}).xarray\n",
    "\n",
    "register_imagestack = partial(\n",
    "    _register_imagestack, reference_image=reference_image, upsample_factor=5\n",
    ")\n",
    "transforms = projection.transform(register_imagestack, group_by={Axes.ROUND}, n_processes=1)\n",
    "round_to_tf = {axes[Axes.ROUND]: tf for tf, axes in transforms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x15ab8b748>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-39., -52.]), array([0., 0.]), array([ 0., -1.])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.translation for t in round_to_tf.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 137.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# starfish doesn't have a great ability to apply different functions to different parts of an\n",
    "# imagestack based on their Axes. It would be great if one could iterate over the ImageStack\n",
    "# and apply a set of transformations to each tile based on the tile's coordinates.\n",
    "\n",
    "def _warp_tile(tile, transform):\n",
    "    round_ = int(tile.coords[Axes.ROUND.value])\n",
    "return warp(np.squeeze(tile), transforms[round_])\n",
    "\n",
    "def warp_imagestack(imagestack, transform_set, chunk_by):\n",
    "\n",
    "    new = starfish.ImageStack.from_numpy_array(np.zeros_like(imagestack.xarray.values))\n",
    "\n",
    "    selectors = product(*(list(int(i) for i in imagestack.xarray.coords[c]) for c in chunk_by))\n",
    "    for s in selectors:\n",
    "        selector = dict(zip(chunk_by, s))\n",
    "        data = np.squeeze(imagestack.xarray.sel(selector))\n",
    "        res = warp(data, transform_set[selector[Axes.ROUND.value]])\n",
    "        new.set_slice(selector, res.astype(np.float32))\n",
    "\n",
    "    return new\n",
    "\n",
    "\n",
    "transformed = warp_imagestack(z_projected_image, round_to_tf, chunk_by=(\"r\", \"c\", \"z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1513c9828>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-pass filter to remove camera noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 266.95it/s]\n"
     ]
    }
   ],
   "source": [
    "ghp = starfish.image.Filter.GaussianHighPass(sigma=1)\n",
    "high_passed = ghp.run(z_projected_image, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct for bleed-through from Illumina SBS reagents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this can be replaced with Kevin's linear unmixing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 43.94it/s]\n"
     ]
    }
   ],
   "source": [
    "bleed_correction_factors = pd.DataFrame(\n",
    "    data=[\n",
    "        [0, 1, 0.05],\n",
    "        [0, 2, 0],\n",
    "        [0, 3, 0],\n",
    "        [1, 0, 0.35],\n",
    "        [1, 2, 0],\n",
    "        [1, 3, 0],\n",
    "        [2, 0, 0],\n",
    "        [2, 1, 0.02],\n",
    "        [2, 3, 0.84],\n",
    "        [3, 0, 0],\n",
    "        [3, 1, 0],\n",
    "        [3, 2, 0.05]\n",
    "    ],\n",
    "    columns=(('bleed_from', 'bleed_into', 'factor_bleed_from_into')),\n",
    ")\n",
    "\n",
    "\n",
    "def do_bleed_correction(stack):\n",
    "    bleed_corrected = deepcopy(stack)\n",
    "\n",
    "    for index, (ch1, ch2, constant) in tqdm(bleed_correction_factors.iterrows()):\n",
    "        bleed = stack.get_slice({Axes.CH: int(ch1)})[0] * constant\n",
    "        img_to_correct = stack.get_slice({Axes.CH: int(ch2)})[0]\n",
    "        corrected = np.maximum(img_to_correct - bleed, 0)\n",
    "        bleed_corrected.set_slice(\n",
    "            {Axes.CH: int(ch2)},\n",
    "            corrected,\n",
    "            axes=[Axes.ROUND, Axes.ZPLANE]\n",
    "        )\n",
    "    return bleed_corrected\n",
    "\n",
    "\n",
    "bleed_corrected = do_bleed_correction(high_passed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove image background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1055a3dd8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(bleed_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = starfish.image.Filter.Clip(p_min=90, p_max=99.9)\n",
    "clipped = clip.run(bleed_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1515f34e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 295.01it/s]\n"
     ]
    }
   ],
   "source": [
    "wth = starfish.image.Filter.WhiteTophat(masking_radius=10)\n",
    "background_corrected = ghp.run(bleed_corrected, in_place=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starfish",
   "language": "python",
   "name": "starfish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
